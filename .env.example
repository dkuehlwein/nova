# Development Logging (human-readable console output)
LOG_JSON=false
LOG_LEVEL=INFO
LOG_FILE_ENABLED=True
# Path to log file (defaults to ./logs/{service_name}.log)  
LOG_FILE_PATH=None  
LOG_FILE_MAX_SIZE_MB=10  
LOG_FILE_BACKUP_COUNT=5  


# LLM Configuration
GOOGLE_API_KEY="your_api_key"

# LiteLLM Configuration (Tier 2: Deployment Environment)
LITELLM_BASE_URL=http://localhost:4000
LITELLM_MASTER_KEY=sk-1234


# llama.cpp Configuration (Tier 2: Deployment Environment)
LLAMACPP_BASE_URL=http://localhost:8080

# Hugging Face API Token (get from https://huggingface.co/settings/tokens)  
HF_TOKEN=your_hf_token_here

# OpenRouter API Key (get from https://openrouter.ai/keys)
OPENROUTER_API_KEY=sk-or-v1-your_openrouter_key_here 

# LangSmith Configuration
LANGCHAIN_TRACING_V2=true
LANGCHAIN_ENDPOINT="https://api.smith.langchain.com"
LANGCHAIN_API_KEY="your-langsmith-api-key"
LANGCHAIN_PROJECT="your-project-name" 

# PostgreSQL Database Configuration
POSTGRES_DB=nova_kanban
POSTGRES_USER=nova
POSTGRES_PASSWORD=nova_dev_password
POSTGRES_PORT=5432

# Neo4j Database Configuration
NEO4J_DB=nova-memory
NEO4J_USER=neo4j
NEO4J_PASSWORD=password
NEO4J_PORT=7687

# Memory Configuration  
MEMORY_GROUP_ID=nova
MEMORY_SEARCH_LIMIT=10

# Email Integration Configuration
EMAIL_ENABLED=true


# Backend APIs

# Redis Configuration  
# Note: localhost for local dev, redis:6379 for Docker (auto-detected)

# Service Ports
HOST=0.0.0.0
PORT=8000
CORE_AGENT_PORT=8001

# Optional: Development flags
SQL_DEBUG=false
CREATE_TABLES=true
CORS_ORIGINS=http://localhost:3000,http://localhost:3001

# Optional: Flower Monitoring
FLOWER_USER=admin
FLOWER_PASSWORD=admin

# MCP Server Configurations
# Note: URLs auto-detected based on environment (localhost vs Docker service names)

