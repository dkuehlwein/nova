model_list:
  # Google Gemini models (cloud)
  - model_name: gemini-2.5-flash
    litellm_params:
      model: gemini/gemini-2.5-flash
      api_key: os.environ/GOOGLE_API_KEY
  
  - model_name: gemini-2.5-flash-preview-04-17
    litellm_params:
      model: gemini/gemini-2.5-flash-preview-04-17
      api_key: os.environ/GOOGLE_API_KEY
  
  # llama.cpp local models
  - model_name: DeepSeek-R1-0528-Qwen3-8B-UD-Q8_K_XL
    litellm_params:
      model: openai/DeepSeek-R1-0528-Qwen3-8B-UD-Q8_K_XL
      api_base: http://llamacpp:8080/v1
      api_key: "not-required"

general_settings:
  master_key: "sk-1234"
  
  # Enable UI for monitoring
  ui_access_mode: "admin_only"
  
  # Default model fallback strategy
  fallbacks:
    - DeepSeek-R1-0528-Qwen3-8B-UD-Q8_K_XL: [gemini-2.5-flash]
    - gemini-2.5-flash: [DeepSeek-R1-0528-Qwen3-8B-UD-Q8_K_XL]

litellm_settings:
  # Enable detailed logging
  set_verbose: true
  
  # Request timeout settings
  request_timeout: 60
  
  # Retry settings
  num_retries: 3