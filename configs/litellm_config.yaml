# No static models defined - all models are added dynamically at startup
# This ensures only working models are available and prevents accumulation of outdated models

model_list: []

# Models are now managed dynamically:
# - Gemini models: Added if Google API key is valid
# - Local models: Added if underlying services (llama.cpp) are running  
# - HuggingFace models: Added if HF token is valid and services are available

general_settings:
  master_key: "sk-1234"
  
  # Enable UI for monitoring
  ui_access_mode: "admin_only"
  
  # Disable database persistence for models and logs
  store_model_in_db: false
  
  # Default model fallback strategy (updated dynamically when Gemini models are available)
  fallbacks:
    # No fallbacks defined here - managed dynamically by LLM service

litellm_settings:
  # Enable detailed logging
  set_verbose: true
  
  # Request timeout settings
  request_timeout: 60
  
  # Retry settings
  num_retries: 3
  
  # Use memory-only caching
  cache: true
  cache_params:
    type: "memory"