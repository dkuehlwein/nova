# No static models defined - all models are added dynamically at startup
# This ensures only working models are available and prevents accumulation of outdated models

model_list: []

# Models are now managed dynamically:
# - Gemini models: Added if Google API key is valid
# - Local models: Added if underlying services (llama.cpp) are running  
# - HuggingFace models: Added if HF token is valid and services are available

general_settings:
  master_key: "sk-1234"
  
  # Enable UI for monitoring
  ui_access_mode: "admin_only"
  
  # Enable database persistence for virtual key management
  # Required for proper service authentication and spend tracking
  store_model_in_db: true
  
  # Enable virtual key management for service authentication
  enable_key_management: true
  
  # Database URL for virtual key storage (set via environment)
  database_url: null  # Set via DATABASE_URL environment variable
  
  # Default model fallback strategy (updated dynamically when Gemini models are available)
  fallbacks:
    # No fallbacks defined here - managed dynamically by LLM service

litellm_settings:
  # Enable detailed logging
  set_verbose: true
  
  # Request timeout settings
  request_timeout: 60
  
  # Retry settings
  num_retries: 3
  
  # Disable caching to avoid startup issues
  cache: false
  
  # Drop unsupported parameters (fixes Gemini embedding compatibility)
  drop_params: true