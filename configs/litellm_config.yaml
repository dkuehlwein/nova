model_list:
  # llama.cpp local models (always available)
  # Phi-4 (supports function calling) - PRIMARY MODEL
  - model_name: phi-4-Q4_K_M
    litellm_params:
      model: openai/phi-4-Q4_K_M
      api_base: http://llamacpp:8080/v1
      api_key: "not-required"
  
  # Google Gemini models are now added dynamically via API when valid Google API key is available
  # This prevents exposure of unusable models when no Google API key is configured

general_settings:
  master_key: "sk-1234"
  
  # Enable UI for monitoring
  ui_access_mode: "admin_only"
  
  # Default model fallback strategy (updated dynamically when Gemini models are available)
  fallbacks:
    # No fallbacks defined here - managed dynamically by LLM service

litellm_settings:
  # Enable detailed logging
  set_verbose: true
  
  # Request timeout settings
  request_timeout: 60
  
  # Retry settings
  num_retries: 3